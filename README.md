# 1. АА_simulation.
### Из проведенного А/А-теста необходимо было сделать симуляцию, как будто мы провели 10000 А/А-тестов. На каждой итерации нужно было сформировать подвыборки без повторения в 500 юзеров из экспериментальных групп. Провести сравнение этих подвыборок t-testом.
### Необходимо:
 - построить гистограмму распределения получившихся 10000 p-values;
 - посчитать, какой процент p values оказался меньше либо равен 0.05;
 - сделать вывод по проведенному А/А-тесту, корректно ли работает система сплитования.
# 2. AB_test.
### Задача — проанализировать данные проведенного А/B-теста. Сравните данные следующими тестами:
- t-тест,
- Пуассоновский бутстреп, 
- тест Манна-Уитни, 
- t-тест на сглаженном CTR (α=5),
- t-тест поверх бакетного преобразования,
- тест Манна-Уитни поверх бакетного преобразования.
### Необходимо посмотреть на распределения, ответить на вопрос: "Почему тесты сработали так как сработали?" Описать потенциальную ситуацию, когда такое изменение могло произойти. Написать рекомендацию, следует ли раскатывать новый алгоритм на всех новых пользователей или все-таки не стоит.
# 3. linearized_likes.
### Вместо того, чтобы заталкивать в тест «поюзерные» CTR, можно сконструировать другую метрику и анализировать ее, но при этом гарантируется (в отличие от сглаженного CTR), что если тест на этой другой метрике «прокрасится» и увидит изменения, значит изменения есть и в метрике исходной (то есть в лайках на пользователя и в пользовательских CTR). Метод простой - гарантируется, что при приличном размере выборки можно бесплатно увеличить чувствительность метрики (или, по крайней мере, не сделать хуже).
